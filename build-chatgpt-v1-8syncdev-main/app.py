import streamlit as st
from langchain_core.prompts import ChatPromptTemplate
from langchain_ollama.llms import OllamaLLM

# Thiáº¿t láº­p trang
st.set_page_config(
    page_title="Hotel Booking Assistant",
    page_icon="ğŸ¨",
    layout="wide"
)

# Táº¡o tiÃªu Ä‘á» vÃ  mÃ´ táº£
st.title("ğŸ¨ Hotel Booking Assistant")
st.markdown("""
ChÃ o má»«ng báº¡n Ä‘áº¿n vá»›i há»‡ thá»‘ng há»— trá»£ Ä‘áº·t phÃ²ng khÃ¡ch sáº¡n! TÃ´i cÃ³ thá»ƒ giÃºp báº¡n:
- ğŸ“‹ Giá»›i thiá»‡u cÃ¡c loáº¡i phÃ²ng vÃ  tiá»‡n Ã­ch
- ğŸ” TÃ¬m kiáº¿m phÃ²ng theo yÃªu cáº§u
- ğŸ’° TÆ° váº¥n Ä‘áº·t phÃ²ng (giÃ¡, thá»i gian, vá»‹ trÃ­)
- â“ Tráº£ lá»i cÃ¢u há»i thÆ°á»ng gáº·p
- ğŸ› ï¸ Há»— trá»£ ká»¹ thuáº­t vÃ  khiáº¿u náº¡i
""")

# Khá»Ÿi táº¡o session state
if "messages" not in st.session_state:
    st.session_state.messages = []

# Táº¡o template cho cÃ¢u há»i vÃ  cÃ¢u tráº£ lá»i
template = """Báº¡n lÃ  má»™t trá»£ lÃ½ Ä‘áº·t phÃ²ng khÃ¡ch sáº¡n chuyÃªn nghiá»‡p. HÃ£y tráº£ lá»i cÃ¢u há»i cá»§a khÃ¡ch hÃ ng má»™t cÃ¡ch thÃ¢n thiá»‡n vÃ  há»¯u Ã­ch.

Context: KhÃ¡ch sáº¡n cÃ³ cÃ¡c loáº¡i phÃ²ng sau:
- PhÃ²ng Deluxe: 2 triá»‡u/Ä‘Ãªm, 35m2, giÆ°á»ng King, view thÃ nh phá»‘
- PhÃ²ng Suite: 3 triá»‡u/Ä‘Ãªm, 50m2, giÆ°á»ng King, view biá»ƒn
- PhÃ²ng Family: 4 triá»‡u/Ä‘Ãªm, 70m2, 2 giÆ°á»ng Queen, view biá»ƒn

Tiá»‡n Ã­ch khÃ¡ch sáº¡n:
- Há»“ bÆ¡i vÃ´ cá»±c
- PhÃ²ng gym 24/7
- NhÃ  hÃ ng 5 sao
- Spa & Massage
- Dá»‹ch vá»¥ Ä‘Æ°a Ä‘Ã³n sÃ¢n bay

CÃ¢u há»i cá»§a khÃ¡ch hÃ ng: {question}

HÃ£y tráº£ lá»i theo cÃ¡c nguyÃªn táº¯c:
1. LuÃ´n thÃ¢n thiá»‡n vÃ  chuyÃªn nghiá»‡p
2. Cung cáº¥p thÃ´ng tin chÃ­nh xÃ¡c vá» giÃ¡ vÃ  tiá»‡n Ã­ch
3. Náº¿u khÃ´ng biáº¿t cÃ¢u tráº£ lá»i, hÃ£y chuyá»ƒn Ä‘áº¿n bá»™ pháº­n há»— trá»£
4. Äá» xuáº¥t cÃ¡c lá»±a chá»n phÃ¹ há»£p vá»›i nhu cáº§u cá»§a khÃ¡ch hÃ ng
5. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t

Tráº£ lá»i:"""

# Táº¡o prompt template
prompt = ChatPromptTemplate.from_template(template)

# Khá»Ÿi táº¡o model
model = OllamaLLM(
    model="mistral",
    temperature=0.7,
    num_ctx=2048,
    num_thread=4
)

# Káº¿t há»£p prompt vÃ  model
chain = prompt | model

# Hiá»ƒn thá»‹ lá»‹ch sá»­ chat
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Táº¡o input cho ngÆ°á»i dÃ¹ng
if question := st.chat_input("Báº¡n cáº§n tÃ´i giÃºp gÃ¬?"):
    # ThÃªm cÃ¢u há»i vÃ o lá»‹ch sá»­
    st.session_state.messages.append({"role": "user", "content": question})
    
    # Hiá»ƒn thá»‹ cÃ¢u há»i
    with st.chat_message("user"):
        st.markdown(question)
    
    # Táº¡o cÃ¢u tráº£ lá»i
    with st.chat_message("assistant"):
        with st.spinner("Äang tÃ¬m thÃ´ng tin..."):
            response = chain.invoke({"question": question})
            st.markdown(response)
            
            # ThÃªm cÃ¢u tráº£ lá»i vÃ o lá»‹ch sá»­
            st.session_state.messages.append({"role": "assistant", "content": response})

# ThÃªm sidebar vá»›i thÃ´ng tin bá»• sung
with st.sidebar:
    st.header("ğŸ“ LiÃªn há»‡ há»— trá»£")
    st.markdown("""
    - Hotline: 1900 1234
    - Email: support@hotel.com
    - Giá» lÃ m viá»‡c: 24/7
    """)
    
    st.header("ğŸ·ï¸ Khuyáº¿n mÃ£i")
    st.markdown("""
    - Giáº£m 20% cho Ä‘áº·t phÃ²ng trÆ°á»›c 7 ngÃ y
    - Miá»…n phÃ­ bá»¯a sÃ¡ng cho khÃ¡ch VIP
    - GÃ³i spa 50% cho khÃ¡ch Ä‘áº·t phÃ²ng Suite
    """) 